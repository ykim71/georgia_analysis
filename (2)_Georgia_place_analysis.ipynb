{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "JgTpKxDx-YMU",
        "R2H0iUp_X1Hh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykim71/georgia_analysis/blob/main/(2)_Georgia_place_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7PpN2VVxH5c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need access to the folder(s) below:\n",
        "\n",
        "#%cd /content/drive/MyDrive/Georgia/\n"
      ],
      "metadata": {
        "id": "aPvEBRBtxzje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Location analysis"
      ],
      "metadata": {
        "id": "5yLkNpuLL3Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for place analysis"
      ],
      "metadata": {
        "id": "JgTpKxDx-YMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis"
      ],
      "metadata": {
        "id": "PFZz3K7xSlBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner2_lem.pkl')\n"
      ],
      "metadata": {
        "id": "7WKF8OS4RkoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = df.sample(10)"
      ],
      "metadata": {
        "id": "bZAcRbtWFkjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatization if needed\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "sp = spacy.load('en_core_web_sm', disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n"
      ],
      "metadata": {
        "id": "Leu0aduT9jp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_ner_place(text):\n",
        "  text = sp(text)\n",
        "  \n",
        "  ner_list = []\n",
        "  \n",
        "  for entity in text.ents:\n",
        "    if entity.label_ == \"FAC\":\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    if entity.label_ == \"GPE\":\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    if entity.label_ == \"LOC\":\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    else:\n",
        "      None\n",
        "  return set(ner_list)\n"
      ],
      "metadata": {
        "id": "r2S86oeO-Pqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_ner_place2(text):\n",
        "  text = sp(text)\n",
        "  \n",
        "  ner_list = []\n",
        "  \n",
        "  for entity in text.ents:\n",
        "    if (entity.label_ == \"FAC\") or  (entity.label_ == \"GPE\") or (entity.label_ == \"LOC\") or (entity.label_ == \"ORG\") :\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    else:\n",
        "      None\n",
        "  return set(ner_list)\n"
      ],
      "metadata": {
        "id": "K778xB3bD2O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_ner_person(text):\n",
        "  text = sp(text)\n",
        "  \n",
        "  ner_list = []\n",
        "  \n",
        "  for entity in text.ents:\n",
        "    if (entity.label_ == \"PERSON\") :\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    else:\n",
        "      None\n",
        "  return set(ner_list)\n"
      ],
      "metadata": {
        "id": "Mt5v5_TBdKSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_ner_all(text):\n",
        "  text = sp(text)\n",
        "  \n",
        "  ner_list = []\n",
        "  \n",
        "  for entity in text.ents:\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "  return set(ner_list)\n"
      ],
      "metadata": {
        "id": "NMblGYHizeSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ner_places'] = df['article_final'].astype(str).apply(text_ner_place)"
      ],
      "metadata": {
        "id": "ydmHijaN-WNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ner_places_orgs'] = df['article_final'].astype(str).apply(text_ner_place2)"
      ],
      "metadata": {
        "id": "TEQrfD6LR6Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ner_person'] = df['article_final'].astype(str).apply(text_ner_person)"
      ],
      "metadata": {
        "id": "AYcGyf32dHS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner3_lem.pkl') # commented this line to prevent from saving it"
      ],
      "metadata": {
        "id": "lKyUNAawaALt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find rough location from spaCy"
      ],
      "metadata": {
        "id": "R2H0iUp_X1Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner2_lem.pkl')\n"
      ],
      "metadata": {
        "id": "vh4PyWlOX0Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner = df.loc[df['ner_places'] != 'set()']"
      ],
      "metadata": {
        "id": "yy41J8P9PlYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "print(len(df_ner))"
      ],
      "metadata": {
        "id": "Uj_17ZSjQeRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand = df_ner['ner_places'].str.split(',').explode().str.strip('{} ')\n"
      ],
      "metadata": {
        "id": "ucqy79j7QbkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand = pd.DataFrame(df_expand)\n"
      ],
      "metadata": {
        "id": "pLmMPrC4Qo0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand['ner_places_clean'] = df_expand['ner_places'].str.replace(r\"\\'\",\"\")\n",
        "df_expand['ner_places_clean'] = df_expand['ner_places_clean'].str.replace(r\" \\\"\",\"\")\n",
        "df_expand['ner_places_clean'] = df_expand['ner_places_clean'].str.replace(r\"\\\"\",\"\")\n",
        "df_expand['ner_places_clean'] = df_expand['ner_places_clean'].str.replace(r\"\\(.*\\)\",\"\")"
      ],
      "metadata": {
        "id": "NPh4arGwQqEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand_count = df_expand.groupby('ner_places_clean').count().reset_index()"
      ],
      "metadata": {
        "id": "40t2DcFSRamc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq_n5 = df_expand_count[df_expand_count[\"ner_places\"] >= 5]\n",
        "df_freq_n5.to_excel('df_freq_n5_ner_v2.xlsx')"
      ],
      "metadata": {
        "id": "fdLEo3K0Rt71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # compare place entities with v1\n",
        "\n",
        "# df_freq_n5_v2 = pd.read_excel('df_freq_n5_ner_v2.xlsx')\n",
        "# df_freq_n5_v1 = pd.read_excel('df_freq_n5_ner.xlsx')\n",
        "\n",
        "# df_freq_n5_v1['version'] = 'v1'\n",
        "# df_freq_n5_v2['version'] = 'v2'\n",
        "\n",
        "# df_freq_n5_merge = pd.merge( df_freq_n5_v1,df_freq_n5_v2, how=\"outer\", on=[\"ner_places_clean\"])"
      ],
      "metadata": {
        "id": "TG-YAtO6xsDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis/Validation_test"
      ],
      "metadata": {
        "id": "h8y-v--yUimk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner3_lem.pkl')\n"
      ],
      "metadata": {
        "id": "pvAaier1QK10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org = df.loc[df['ner_places_orgs'] != 'set()']\n",
        "df_ner_person = df.loc[df['ner_person'] != 'set()']"
      ],
      "metadata": {
        "id": "Rx7fED4yQRp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org_expand = df_ner_place_org['ner_places_orgs'].explode()\n",
        "df_ner_person_expand = df_ner_person['ner_person'].explode()\n"
      ],
      "metadata": {
        "id": "Jbs6K79VQRI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org_expand = pd.DataFrame(df_ner_place_org_expand)\n",
        "df_ner_person_expand = pd.DataFrame(df_ner_person_expand)\n"
      ],
      "metadata": {
        "id": "QzegpIqlSIyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org_expand['ner_clean'] = df_ner_place_org_expand['ner_places_orgs'].str.replace(r\" \\(.*\\)\",\"\")\n",
        "df_ner_person_expand['ner_clean'] = df_ner_person_expand['ner_person'].str.replace(r\" \\(.*\\)\",\"\")"
      ],
      "metadata": {
        "id": "gouBK22BSZ-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org_expand = df_ner_place_org_expand.dropna()\n",
        "df_ner_person_expand = df_ner_person_expand.dropna()"
      ],
      "metadata": {
        "id": "Xlcly82WSuVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org_expand['ner_clean'] = df_ner_place_org_expand['ner_clean'].str.strip()\n",
        "df_ner_person_expand['ner_clean'] = df_ner_person_expand['ner_clean'].str.strip()"
      ],
      "metadata": {
        "id": "d-wcfgc9X3sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_person_expand"
      ],
      "metadata": {
        "id": "XSKPRkOcX5mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner_place_org_count = df_ner_place_org_expand.groupby('ner_clean').count().reset_index()\n",
        "df_ner_person_count = df_ner_person_expand.groupby('ner_clean').count().reset_index()"
      ],
      "metadata": {
        "id": "Cm6-KCWmThk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_ner_place_org_count))\n",
        "print(len(df_ner_person_count))"
      ],
      "metadata": {
        "id": "8bi0ZTFlUqEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq_place_org_n5 = df_ner_place_org_count[df_ner_place_org_count[\"ner_places_orgs\"] >= 5]\n",
        "df_freq_person_n5 = df_ner_person_count[df_ner_person_count[\"ner_person\"] >= 5]\n"
      ],
      "metadata": {
        "id": "CgUyxCAbUt-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_freq_place_org_n5))\n",
        "print(len(df_freq_person_n5))"
      ],
      "metadata": {
        "id": "PFtQv-Q0VSQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq_place_org_n5.to_excel('df_freq_place_org_n5.xlsx')"
      ],
      "metadata": {
        "id": "8O74FTaVY7pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_freq_person_n5.to_excel('df_freq_person_n5.xlsx')"
      ],
      "metadata": {
        "id": "pd9VZx3EVtrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find sentence example of location"
      ],
      "metadata": {
        "id": "Ggu0MvMFQmx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#ner_places = pd.read_csv('Georgia_ner_places.csv') # previous data\n",
        "#ner_places = pd.read_csv('Georgia_ner_places_v2.csv') # updated data\n",
        "ner_places = pd.read_excel('Georgia_place_review_final_validation.xlsx') # updated data"
      ],
      "metadata": {
        "id": "ZU1S_6coQpR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ner_places['ner_places_clean'] = ner_places['ner_places_clean'].str.rstrip()"
      ],
      "metadata": {
        "id": "Dd9WWAzOR4D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_places_raw = list(set(ner_places['ner_places_clean2'].tolist()))"
      ],
      "metadata": {
        "id": "XLlz4OzHRpob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner2_lem.pkl')\n",
        "\n",
        "# remove bracket and quotes\n",
        "df['ner_places_clean'] = df['ner_places'].apply(lambda x: re.sub(r'[{}]', '', x))\n",
        "#df['ner_places_clean'] = df['ner_places_clean'].str.replace(r\" \\(GPE\\)\",\"\")\n",
        "df['ner_places_clean'] = df['ner_places_clean'].str.replace(r\"\\', \\'\", \" \")\n",
        "df['ner_places_clean'] = df['ner_places_clean'].str.rstrip(\"'\")\n",
        "df['ner_places_clean'] = df['ner_places_clean'].str.lstrip(\"'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BLg2CGksWuZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "EWfelpd-Q7zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def bigrams(s):\n",
        "    return [i for i in s if re.search(r'\\s', i) ]\n",
        "  \n",
        "def unigrams(s):\n",
        "    return [i for i in s if not re.search(r'\\s', i) ]\n",
        "\n",
        "word_bigrams_done = list(set(bigrams(ner_places_raw)))\n",
        "print(word_bigrams_done)\n",
        "print(len(word_bigrams_done))\n",
        "                       \n",
        "word_unigrams_done = unigrams(ner_places_raw)\n",
        "print(word_unigrams_done)\n",
        "print(len(word_unigrams_done))\n"
      ],
      "metadata": {
        "id": "7od0UrvGXYt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only for what spaCy found\n",
        "\n",
        "df['place_ner1'] = df['ner_places_clean'].astype(str).apply(lambda x: set.intersection(set(x.split(' ')), word_unigrams_done))\n",
        "df['place_ner2'] = df['ner_places_clean'].astype(str).apply(lambda x: [i for i in word_bigrams_done if i in x])\n"
      ],
      "metadata": {
        "id": "aPE8Wa1XXaQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ner identification\n",
        "\n",
        "df_uni2 = df[(df['place_ner1'].str.len()) >= 1]\n",
        "df_bi2 = df[(df['place_ner2'].str.len()) >= 1]\n",
        "\n",
        "df_uni2 = df_uni2[['id', 'source', 'place_ner1', 'article_final']]\n",
        "df_bi2 = df_bi2[['id', 'source', 'place_ner2', 'article_final']]\n",
        "\n",
        "df_uni_df2 = df_uni2.explode('place_ner1')\n",
        "df_bi_df2 = df_bi2.explode('place_ner2')\n",
        "\n",
        "df_uni_df2 = df_uni_df2.rename(columns={'place_ner1': 'place_ner'})\n",
        "df_bi_df2 = df_bi_df2.rename(columns={'place_ner2': 'place_ner'})\n",
        "\n",
        "df_ng_all2 = pd.concat([df_uni_df2, df_bi_df2])"
      ],
      "metadata": {
        "id": "BpnUAJPhXdAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all2"
      ],
      "metadata": {
        "id": "-xeJVvdJgd5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentence = df_ng_all2[['id', 'article_final']].drop_duplicates(subset=['id', 'article_final'])"
      ],
      "metadata": {
        "id": "wGq-1HJcY4Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split an article into sentences\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "by_sentence = df_sentence['article_final'].apply(lambda x : sent_tokenize(x)).apply(pd.Series,1).stack()\n",
        "by_sentence_df = pd.DataFrame(by_sentence)\n",
        "by_sentence_df.rename(columns={0:'sentence_each'}, inplace=True)\n",
        "\n",
        "by_sentence_df['sentence_turn'] = by_sentence_df.index.get_level_values(1)\n",
        "by_sentence_df.index = by_sentence_df.index.get_level_values(0)\n"
      ],
      "metadata": {
        "id": "-eri3IbAYzcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni = pd.merge(df_ng_all2, by_sentence_df, left_index=True, right_index=True)\n"
      ],
      "metadata": {
        "id": "XG3Hpg9GTFFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni['search_words'] = merge_uni.apply(lambda x: x.place_ner in x.sentence_each, axis=1)\n",
        "\n",
        "merge_uni_TRUE = merge_uni[merge_uni['search_words']==True]"
      ],
      "metadata": {
        "id": "fcHSmbdKb_DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_TRUE_st = merge_uni_TRUE[['id','source','place_ner','sentence_each']]"
      ],
      "metadata": {
        "id": "QIMhsCTPa2of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp = merge_uni_TRUE_st.groupby('place_ner').count() #"
      ],
      "metadata": {
        "id": "cR78RbChbAYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp"
      ],
      "metadata": {
        "id": "707-_3EMczoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# articles mentioned a location less than 3\n",
        "merge_temp_less10 = merge_temp[merge_temp['sentence_each'] < 10].reset_index()\n"
      ],
      "metadata": {
        "id": "7mMK-srPLvtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_less10_places = merge_temp_less10.place_ner.values.tolist()\n"
      ],
      "metadata": {
        "id": "9GCZ_VtNLyt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_temp_less10_places)"
      ],
      "metadata": {
        "id": "MSwdMLUOekJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_TRUE_st_less10 = merge_uni_TRUE_st[merge_uni_TRUE_st['place_ner'].isin(merge_temp_less10_places)]\n"
      ],
      "metadata": {
        "id": "7Nb6l6aAcraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# articles mentioned a location more than 3 --> random sample\n",
        "\n",
        "merge_uni_TRUE_st_rest = merge_uni_TRUE_st[~merge_uni_TRUE_st['place_ner'].isin(merge_temp_less10_places)]\n",
        "merge_uni_TRUE_st_more10 = merge_uni_TRUE_st_rest.groupby('place_ner').apply(lambda x: x.sample(10, replace=False)).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "ikE7eLK3L4eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_TRUE_st_more10"
      ],
      "metadata": {
        "id": "fXHMYjTMbK_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge 3 samples + those with less than 3 \n",
        "merge_all = pd.concat([merge_uni_TRUE_st_more10, merge_uni_TRUE_st_less10]).reset_index()"
      ],
      "metadata": {
        "id": "TrUO6epMhDjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all = merge_all.sort_values('place_ner')"
      ],
      "metadata": {
        "id": "IuA8GtipjnN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all['sentenceID'] = merge_all.groupby('place_ner')['place_ner'].rank(method='first')\n"
      ],
      "metadata": {
        "id": "H_ta7WfUkRgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all"
      ],
      "metadata": {
        "id": "BiNKPGHkmz-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot = merge_all.pivot(index='place_ner', columns = 'sentenceID', values='sentence_each').reset_index()\n"
      ],
      "metadata": {
        "id": "9ZfRNhH_jB-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot.rename(columns={1:'s1', 2:'s2', 3:'s3', 4:'s4', 5:'s5', 6:'s6', 7:'s7', 8:'s8', 9:'s9', 10:'s10'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "s7DqboNzUDOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ner_places_raw)"
      ],
      "metadata": {
        "id": "6c3RipP1g6v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(set(ner_places_raw) - set(merge_all_pivot['place_ner'].values.tolist())))"
      ],
      "metadata": {
        "id": "FD70GoGNh9u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list(set(ner_places_raw) - set(merge_all_pivot['place_ner'].values.tolist()))"
      ],
      "metadata": {
        "id": "9zcHl6snhefo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge_temp_final['sent_1'] = merge_temp_final['sent_1'].str.replace('\\n', ' ')\n",
        "# merge_temp_final['sent_2'] = merge_temp_final['sent_2'].str.replace('\\n', ' ')\n",
        "# merge_temp_final['sent_3'] = merge_temp_final['sent_3'].str.replace('\\n', ' ')"
      ],
      "metadata": {
        "id": "rEJHlTVfhavY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_places['place_ner'] = ner_places['ner_places_clean2']\n",
        "ner_places_st = ner_places[['place_ner', 'address', 'address_ga', 'address_usa']]"
      ],
      "metadata": {
        "id": "Csw5rMHJmg1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot_merge = pd.merge(merge_all_pivot, ner_places_st, on=\"place_ner\", how='left')\n"
      ],
      "metadata": {
        "id": "zDopHL8lnnGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mt. Pisgah\n",
        "merge_all_pivot_merge.to_excel('/content/drive/MyDrive/Georgia/Locations Analysis/COPY_Georgia_ner_places_validation_10_sent_example.xlsx')"
      ],
      "metadata": {
        "id": "Z2lYrXCaprjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "merge_all_pivot_merge = pd.read_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Georgia_ner_places_validation_10_sent_example.xlsx')\n"
      ],
      "metadata": {
        "id": "ZZ2iC99tzSxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_all_pivot_merge)"
      ],
      "metadata": {
        "id": "tgKh_-hG1qQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_all_pivot_merge)-2686"
      ],
      "metadata": {
        "id": "uOHD8X4G0K5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# those only with more than 10 examples\n",
        "merge_all_pivot_merge_filter = merge_all_pivot_merge.dropna(subset=['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10' ])"
      ],
      "metadata": {
        "id": "WTa69xRxzwg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot_merge_filter.to_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Georgia_ner_places_validation_10_sent_example.xlsx')"
      ],
      "metadata": {
        "id": "RgS7ZW4C0qqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## find examples of PERSON ner\n",
        "\n",
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "ner_person = pd.read_excel('df_person_results_GA_TRUE_wide.xlsx')\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner3_lem.pkl')\n"
      ],
      "metadata": {
        "id": "SxotR1O5Hl5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "T0qZg2DITpZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_person_raw = list(set(ner_person['ner_original'].tolist()))"
      ],
      "metadata": {
        "id": "lBm3CfADIpA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import re\n",
        "\n",
        "def bigrams(s):\n",
        "    return [i for i in s if re.search(r'\\s', i) ]\n",
        "  \n",
        "def unigrams(s):\n",
        "    return [i for i in s if not re.search(r'\\s', i) ]\n",
        "\n",
        "word_bigrams_done = list(set(bigrams(ner_person_raw)))\n",
        "print(word_bigrams_done)\n",
        "print(len(word_bigrams_done))\n",
        "                       \n",
        "word_unigrams_done = unigrams(ner_person_raw)\n",
        "print(word_unigrams_done)\n",
        "print(len(word_unigrams_done))\n",
        "\n"
      ],
      "metadata": {
        "id": "urHsN_40IXa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove bracket and quotes\n",
        "df['ner_places_orgs_clean'] = df['ner_places_orgs'].astype(str).apply(lambda x: re.sub(r'[{}]', '', x))\n",
        "#df['ner_places_clean'] = df['ner_places_clean'].str.replace(r\" \\(GPE\\)\",\"\")\n",
        "df['ner_places_orgs_clean'] = df['ner_places_orgs_clean'].str.replace(r\"\\', \\'\", \" \")\n",
        "df['ner_places_orgs_clean'] = df['ner_places_orgs_clean'].str.rstrip(\"'\")\n",
        "df['ner_places_orgs_clean'] = df['ner_places_orgs_clean'].str.lstrip(\"'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OdGflXnZUISK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove bracket and quotes\n",
        "df['ner_person_clean'] = df['ner_person'].astype(str).apply(lambda x: re.sub(r'[{}]', '', x))\n",
        "#df['ner_places_clean'] = df['ner_places_clean'].str.replace(r\" \\(GPE\\)\",\"\")\n",
        "df['ner_person_clean'] = df['ner_person_clean'].str.replace(r\"\\', \\'\", \" \")\n",
        "df['ner_person_clean'] = df['ner_person_clean'].str.rstrip(\"'\")\n",
        "df['ner_person_clean'] = df['ner_person_clean'].str.lstrip(\"'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "G0pkzdXhI-3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# only for what spaCy found\n",
        "\n",
        "df['person_ner1'] = df['ner_person_clean'].astype(str).apply(lambda x: set.intersection(set(x.split(' ')), word_unigrams_done))\n",
        "df['person_ner2'] = df['ner_person_clean'].astype(str).apply(lambda x: [i for i in word_bigrams_done if i in x])\n",
        "\n"
      ],
      "metadata": {
        "id": "yaNXAtOFLJtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# only for what spaCy found\n",
        "\n",
        "df['person_ner3'] = df['ner_places_orgs_clean'].astype(str).apply(lambda x: set.intersection(set(x.split(' ')), word_unigrams_done))\n",
        "df['person_ner4'] = df['ner_places_orgs_clean'].astype(str).apply(lambda x: [i for i in word_bigrams_done if i in x])\n",
        "\n"
      ],
      "metadata": {
        "id": "nJ6P4Xe3UPPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ner identification\n",
        "\n",
        "df_temp1 = df[(df['person_ner1'].str.len()) >= 1]\n",
        "df_temp2 = df[(df['person_ner2'].str.len()) >= 1]\n",
        "df_temp3 = df[(df['person_ner3'].str.len()) >= 1]\n",
        "df_temp4 = df[(df['person_ner4'].str.len()) >= 1]\n",
        "\n",
        "df_temp1 = df_temp1[['id', 'source', 'person_ner1', 'article_final']]\n",
        "df_temp2 = df_temp2[['id', 'source', 'person_ner2', 'article_final']]\n",
        "df_temp3 = df_temp3[['id', 'source', 'person_ner3', 'article_final']]\n",
        "df_temp4 = df_temp4[['id', 'source', 'person_ner4', 'article_final']]\n",
        "\n",
        "df_temp1_exp = df_temp1.explode('person_ner1')\n",
        "df_temp2_exp = df_temp2.explode('person_ner2')\n",
        "df_temp3_exp = df_temp3.explode('person_ner3')\n",
        "df_temp4_exp = df_temp4.explode('person_ner4')\n",
        "\n",
        "df_temp1_exp = df_temp1_exp.rename(columns={'person_ner1': 'person_ner'})\n",
        "df_temp2_exp = df_temp2_exp.rename(columns={'person_ner2': 'person_ner'})\n",
        "df_temp3_exp = df_temp3_exp.rename(columns={'person_ner3': 'person_ner'})\n",
        "df_temp4_exp = df_temp4_exp.rename(columns={'person_ner4': 'person_ner'})\n",
        "\n",
        "df_ng_all2 = pd.concat([df_temp1_exp, df_temp2_exp, df_temp3_exp, df_temp4_exp])\n",
        "\n",
        "df_sentence = df_ng_all2[['id', 'article_final']].drop_duplicates(subset=['id', 'article_final'])\n"
      ],
      "metadata": {
        "id": "Lv8JfGN7I5ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_sentence)"
      ],
      "metadata": {
        "id": "MEKz0mmkVdlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# split an article into sentences\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "by_sentence = df_sentence['article_final'].apply(lambda x : sent_tokenize(x)).apply(pd.Series,1).stack()\n",
        "by_sentence_df = pd.DataFrame(by_sentence)\n",
        "by_sentence_df.rename(columns={0:'sentence_each'}, inplace=True)\n",
        "\n",
        "by_sentence_df['sentence_turn'] = by_sentence_df.index.get_level_values(1)\n",
        "by_sentence_df.index = by_sentence_df.index.get_level_values(0)\n",
        "\n",
        "merge_uni = pd.merge(df_ng_all2, by_sentence_df, left_index=True, right_index=True)\n",
        "\n",
        "merge_uni['search_words'] = merge_uni.apply(lambda x: x.person_ner in x.sentence_each, axis=1)\n",
        "\n",
        "merge_uni_TRUE = merge_uni[merge_uni['search_words']==True]"
      ],
      "metadata": {
        "id": "gifJ_zqSORTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_TRUE_st = merge_uni_TRUE[['id','source','person_ner','sentence_each']]\n",
        "merge_temp = merge_uni_TRUE_st.groupby('person_ner').count() #\n"
      ],
      "metadata": {
        "id": "ax1BNEioOo5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# articles mentioned a location less than 10\n",
        "merge_temp_less10 = merge_temp[merge_temp['sentence_each'] < 10].reset_index()\n",
        "merge_temp_less10_places = merge_temp_less10.person_ner.values.tolist()\n"
      ],
      "metadata": {
        "id": "8tLjELEtPx27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_TRUE_st_less10 = merge_uni_TRUE_st[merge_uni_TRUE_st['person_ner'].isin(merge_temp_less10_places)]\n"
      ],
      "metadata": {
        "id": "Vl0GZYoIaIuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_temp_less10_places)"
      ],
      "metadata": {
        "id": "HTr7wQInS44r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# articles mentioned a location more than 10 --> random sample\n",
        "\n",
        "merge_uni_TRUE_st_rest = merge_uni_TRUE_st[~merge_uni_TRUE_st['person_ner'].isin(merge_temp_less10_places)]\n",
        "merge_uni_TRUE_st_more10 = merge_uni_TRUE_st_rest.groupby('person_ner').apply(lambda x: x.sample(10, replace=False)).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DATs-5zsP0TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge 10 samples + those with less than 10 \n",
        "merge_all = pd.concat([merge_uni_TRUE_st_more10, merge_uni_TRUE_st_less10]).reset_index()"
      ],
      "metadata": {
        "id": "Uuz3JgafZ0bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merge_all = merge_all.sort_values('person_ner')\n",
        "merge_all['sentenceID'] = merge_all.groupby('person_ner')['person_ner'].rank(method='first')\n",
        "\n",
        "merge_all_pivot = merge_all.pivot(index='person_ner', columns = 'sentenceID', values='sentence_each').reset_index()\n",
        "\n",
        "merge_all_pivot.rename(columns={1:'s1', 2:'s2', 3:'s3', 4:'s4', 5:'s5', 6:'s6', 7:'s7', 8:'s8', 9:'s9', 10:'s10'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "dYuIagGOPHw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot"
      ],
      "metadata": {
        "id": "KTKh0s3Faj7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_person"
      ],
      "metadata": {
        "id": "LyHM4DW4aPO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ner_person['person_ner'] = ner_person['ner_original']\n",
        "\n",
        "merge_all_pivot_merge = pd.merge(merge_all_pivot, ner_person, on=\"person_ner\", how='left')\n"
      ],
      "metadata": {
        "id": "gCtOI7FIP89I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot_merge.to_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/Georgia_ner_person_validation_10_sent_example.xlsx')\n"
      ],
      "metadata": {
        "id": "LOhnvwGSax21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# those only with more than 10 examples\n",
        "merge_all_pivot_merge_filter = merge_all_pivot_merge.dropna(subset=['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10' ])\n",
        "\n",
        "merge_all_pivot_merge_filter.to_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/Georgia_ner_person_validation_10_sent_example_m10.xlsx')\n"
      ],
      "metadata": {
        "id": "Gk4-SEGobVn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exclude those that are in the ner place worksheet\n",
        "\n",
        "ner_place = pd.read_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Georgia_ner_places_validation_10_sent_example.xlsx')"
      ],
      "metadata": {
        "id": "I2_-gvpEdRti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_place_raw = list(set(ner_place['place_ner'].tolist()))\n",
        "merge_all_pivot_merge_rest = merge_all_pivot_merge[~merge_all_pivot_merge['person_ner'].isin(ner_place_raw)]\n"
      ],
      "metadata": {
        "id": "-XnEYWR_dn94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_all_pivot_merge)"
      ],
      "metadata": {
        "id": "2tioorureLh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_all_pivot_merge_rest)"
      ],
      "metadata": {
        "id": "LgLv4DOheIb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot_merge_rest2 = merge_all_pivot_merge_filter[~merge_all_pivot_merge_filter['person_ner'].isin(ner_place_raw)]\n"
      ],
      "metadata": {
        "id": "yTpnbsI9eQfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_all_pivot_merge_rest2)"
      ],
      "metadata": {
        "id": "kMYoeEXeeTli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_pivot_merge_rest2.to_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/Georgia_ner_person_validation_10_sent_example_m10_rest.xlsx')\n"
      ],
      "metadata": {
        "id": "jNrtppyJenyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look up location (w updated data) on articles"
      ],
      "metadata": {
        "id": "cY1vi4e0QNqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis"
      ],
      "metadata": {
        "id": "rEsOC72WTTib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data created by manual coding\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "location_final = pd.read_excel('Georgia_place_validation_counties.xlsx')"
      ],
      "metadata": {
        "id": "6vkKM1LjQRXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final = location_final[location_final['final_selection']==1]"
      ],
      "metadata": {
        "id": "IhdmM7NvcwJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st = location_final[['ner_place_clean','county_level', 'final_selection']]"
      ],
      "metadata": {
        "id": "qYuxviOCj0FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st = location_final_st.dropna()"
      ],
      "metadata": {
        "id": "l7_56rt2yiVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(location_final_st)"
      ],
      "metadata": {
        "id": "AzUCzxNbmsBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st"
      ],
      "metadata": {
        "id": "MyGCPiwxPcuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # multiple counties deleted\n",
        "# location_final_st = location_final_st[location_final_st['county_level'].str.contains('Counties')==False]"
      ],
      "metadata": {
        "id": "cKbOXVZsmb1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(location_final_st.county_level.values.tolist()))"
      ],
      "metadata": {
        "id": "hFPKsq8gsiaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_list = list(set(location_final_st['ner_place_clean'].tolist()))"
      ],
      "metadata": {
        "id": "d3UqVKMGgFCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner2_lem.pkl')\n"
      ],
      "metadata": {
        "id": "opLFb-2OdJzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove bracket and quotes\n",
        "df['ner_places_clean'] = df['ner_places'].apply(lambda x: re.sub(r'[{}]', '', x))\n",
        "#df['ner_places_clean'] = df['ner_places_clean'].str.replace(r\" \\(GPE\\)\",\"\")\n",
        "df['ner_places_clean'] = df['ner_places_clean'].str.replace(r\"\\', \\'\", \" \")\n",
        "df['ner_places_clean'] = df['ner_places_clean'].str.rstrip(\"'\")\n",
        "df['ner_places_clean'] = df['ner_places_clean'].str.lstrip(\"'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f1hoxb6XZmjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def bigrams(s):\n",
        "    return [i for i in s if re.search(r'\\s', i) ]\n",
        "  \n",
        "def unigrams(s):\n",
        "    return [i for i in s if not re.search(r'\\s', i) ]\n",
        "\n",
        "word_bigrams_done = list(set(bigrams(location_final_list)))\n",
        "print(word_bigrams_done)\n",
        "print(len(word_bigrams_done))\n",
        "                       \n",
        "word_unigrams_done = unigrams(location_final_list)\n",
        "print(word_unigrams_done)\n",
        "print(len(word_unigrams_done))\n"
      ],
      "metadata": {
        "id": "hbjFlI7bdKsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "df['place_ng1'] = df['article_final'].astype(str).apply(lambda x: set.intersection(set(x.split(' ')), word_unigrams_done))\n",
        "df['place_ng2'] = df['article_final'].astype(str).apply(lambda x: [i for i in word_bigrams_done if i in x])\n"
      ],
      "metadata": {
        "id": "GuIb9pjICaGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# only for what spaCy found\n",
        "\n",
        "df['place_ner1'] = df['ner_places_clean'].astype(str).apply(lambda x: set.intersection(set(x.split(' ')), word_unigrams_done))\n",
        "df['place_ner2'] = df['ner_places_clean'].astype(str).apply(lambda x: [i for i in word_bigrams_done if i in x])\n"
      ],
      "metadata": {
        "id": "NuLnSpGCgXyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# article identification\n",
        "\n",
        "df_uni = df[(df['place_ng1'].str.len()) >= 1]\n",
        "df_bi = df[(df['place_ng2'].str.len()) >= 1]\n",
        "\n",
        "df_uni = df_uni[['id', 'source', 'place_ng1']]\n",
        "df_bi = df_bi[['id', 'source', 'place_ng2']]\n",
        "\n",
        "df_uni_df = df_uni.explode('place_ng1')\n",
        "df_bi_df = df_bi.explode('place_ng2')\n",
        "\n",
        "df_uni_df = df_uni_df.rename(columns={'place_ng1': 'place_ner'})\n",
        "df_bi_df = df_bi_df.rename(columns={'place_ng2': 'place_ner'})\n"
      ],
      "metadata": {
        "id": "83NMMSwcggCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all = pd.concat([df_uni_df, df_bi_df])"
      ],
      "metadata": {
        "id": "FbOHNB_whKXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ner identification\n",
        "\n",
        "df_uni2 = df[(df['place_ner1'].str.len()) >= 1]\n",
        "df_bi2 = df[(df['place_ner2'].str.len()) >= 1]\n",
        "\n",
        "df_uni2 = df_uni2[['id', 'source', 'place_ner1']]\n",
        "df_bi2 = df_bi2[['id', 'source', 'place_ner2']]\n",
        "\n",
        "df_uni_df2 = df_uni2.explode('place_ner1')\n",
        "df_bi_df2 = df_bi2.explode('place_ner2')\n",
        "\n",
        "df_uni_df2 = df_uni_df2.rename(columns={'place_ner1': 'place_ner'})\n",
        "df_bi_df2 = df_bi_df2.rename(columns={'place_ner2': 'place_ner'})\n"
      ],
      "metadata": {
        "id": "bVLKHF8hEVww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all2 = pd.concat([df_uni_df2, df_bi_df2])"
      ],
      "metadata": {
        "id": "nwpS8B_4EVmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = df_ng_all.groupby(['source']).count()"
      ],
      "metadata": {
        "id": "xDdANgf1hdTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_20 = count[count['place_ner'] >= 20].reset_index()"
      ],
      "metadata": {
        "id": "tHu85ziIhfyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count2 = df_ng_all2.groupby(['source']).count()"
      ],
      "metadata": {
        "id": "RICKWHAzErbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count2_20 = count2[count2['place_ner'] >= 20].reset_index()"
      ],
      "metadata": {
        "id": "0kQhPeL0EuJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_20"
      ],
      "metadata": {
        "id": "nKnexzgeFD5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count2_20"
      ],
      "metadata": {
        "id": "RM-qVXxgFSmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_20_id = list(set(count_20['source'].tolist()))\n",
        "\n",
        "df_ng_all_m20 = df_ng_all[df_ng_all['source'].isin(count_20_id)]\n"
      ],
      "metadata": {
        "id": "IvB7I52rhsHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(count_20_id)"
      ],
      "metadata": {
        "id": "1awRlpXFkXzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st = location_final_st.rename(columns={'ner_place_clean': 'place_ner'})\n"
      ],
      "metadata": {
        "id": "imJj-NCGkOZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county = pd.merge(df_ng_all_m20, location_final_st, how='left', on='place_ner')"
      ],
      "metadata": {
        "id": "Ry1nnH47h1h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county_unique = df_ng_all_m20_county.drop_duplicates(subset=['id', 'source', 'county_level'])"
      ],
      "metadata": {
        "id": "qeTXN7_YkrEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county_unique_count = df_ng_all_m20_county_unique.groupby(['source','county_level'])['id'].count().reset_index()"
      ],
      "metadata": {
        "id": "RC6nhVn2lbLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county_unique_count = df_ng_all_m20_county_unique_count.rename(columns={'id': 'article_id_count'})\n"
      ],
      "metadata": {
        "id": "yfmDfAVDfV6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county_unique_count.to_excel('Georgia_m20_county_unique_count_v2.xlsx')"
      ],
      "metadata": {
        "id": "ZyOM2c0klvSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take random samples for manual validation"
      ],
      "metadata": {
        "id": "mrLqWfgvYG9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_20 = df.sample(20)"
      ],
      "metadata": {
        "id": "1fhJjwyJxDYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_20.to_excel('Georgia_20_articles_for_place_review.xlsx')"
      ],
      "metadata": {
        "id": "SozgdBXBxF4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_15 = df.sample(15)"
      ],
      "metadata": {
        "id": "pPDvTeeedrg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_15.to_excel('Georgia_15_articles_for_place_review.xlsx')"
      ],
      "metadata": {
        "id": "JqV6rTW9dtny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis/Validation_test"
      ],
      "metadata": {
        "id": "Mn9JjtKW50eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rnd1 = pd.read_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/Copy of Georgia_15_articles_for_place_review.xlsx')\n",
        "rnd2 = pd.read_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/Copy of Georgia_20_articles_for_place_review.xlsx')"
      ],
      "metadata": {
        "id": "EliNbKvB59ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd1_st = rnd1[['id', 'ner_places', 'article_final']]\n",
        "rnd2_st = rnd2[['id', 'ner_places', 'article_final']]"
      ],
      "metadata": {
        "id": "eIrVoIwP6FGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge = pd.concat([rnd1_st, rnd2_st])"
      ],
      "metadata": {
        "id": "bVvyj-S26Ngb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 'MARIETTA — The renovation of northeast Cobb’s Gritters Library, originally budgeted as a $2.9 million project, could soon cost $10.5 million after Tuesday’s Board of Commissioners meeting. The ballooning budget is a result not only of rising construction costs, but of a project that’s now envisioned as a full rebuild of the aging library. The board was expected to vote Tuesday on approving a $2.5 million transfer to fill out the budget, though support for the move appeared to waver at a Monday morning work session. Tucked into the woods alongside Shaw Park off of Canton Road, Gritters, according to Library Director Helen Poyer, “sits in a swampland” and is “an old cedar building that’s in very poor condition.” Major features of the rebuild will include building out reading and study rooms, expanding an existing multipurpose room, creating an outdoor programming space, and consolidating services into a one-stop service desk. Poyer added that in 2014, when the library system lobbied for the building to be put on the 2016 SPLOST list, she already knew a complete rebuild would be required and probably cost about $8.6 million. Instead, the library got just $2.9 million from the SPLOST. Commissioners supplemented that with a $2 million allocation from revenue above projections — extra cash generated by the sales tax. And to top it off, the county received $1.9 million in funding from Georgia’s Board of Regents last year. That brought the budget up to $6.8 million. The county’s also elected to fold in $1.2 million set aside for the Shaw Park community center, consolidating the space into the library itself and bringing the budget to $8 million. The final $2.5 million, if approved, would come from county reserve funds. But Commissioner Keli Gambrill took issue with using general budget dollars to pay for a SPLOST project. “How many other 2016 SPLOST projects that are not completed are going to be in the same position?” she asked. “… If we we knew (the project cost) going into this, and now we’re using general funds — I mean, when’s it going to end?” Sharon Stanley, who heads up the county’s support services agency, said the previous budgets were believed to be sufficient to cover the costs in full. But rising construction prices had brought the price tag north of the $10 million mark, with contractor Batson-Cook offering the current price tag as a guaranteed ceiling. The county saw similar cost overruns with a new police precinct it’s building in northeast Cobb, which required a roughly 10% increase in its budget earlier this year. “If we don’t get funded, or this is not approved, then we’ll be back out on the market again,” said Property Management Director Travis Stalcup. “And then … we’ll just face what we’ve been facing the whole time: escalating material prices, labor shortages.” Commissioner JoAnn Birrell, who represents the area, said she would meet with her colleagues Monday to gauge support for moving forward. “If we don’t (have support), I’m pulling it,” she said. The board will meet at 7 p.m. Tuesday at 100 Cherokee Street in Marietta.\t'"
      ],
      "metadata": {
        "id": "pC1EpgBhC2Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge.iloc[6]['article_final']"
      ],
      "metadata": {
        "id": "7QVtp178AbZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ner_all(temp)"
      ],
      "metadata": {
        "id": "ZqFuLeHb1NdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ner_place(temp)"
      ],
      "metadata": {
        "id": "zYaVb7QuBXsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ner_place2(temp)"
      ],
      "metadata": {
        "id": "F-543HdED_-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp['ner_all'] = df_temp['article_final'].astype(str).apply(text_ner_all)\n",
        "df_temp['ner_place_2nd'] = df_temp['article_final'].astype(str).apply(text_ner_place)"
      ],
      "metadata": {
        "id": "Csy4nbswF0-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp['ner_place_org'] = df_temp['article_final'].astype(str).apply(text_ner_place2)"
      ],
      "metadata": {
        "id": "YqP9VsmuJeP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp"
      ],
      "metadata": {
        "id": "0Ika-zxdJh4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp[['ner_places', 'ner_place_2nd']]"
      ],
      "metadata": {
        "id": "B-km3hQAG41e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge['ner_all'] = set_merge['article_final'].astype(str).apply(text_ner_all)"
      ],
      "metadata": {
        "id": "C98YUnZtzso4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge['ner_place_org'] = set_merge['article_final'].astype(str).apply(text_ner_place2)"
      ],
      "metadata": {
        "id": "NYyAjvHSJrow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge.to_excel(\"/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/spacy_place_org.xlsx\")"
      ],
      "metadata": {
        "id": "eOCVpfUZzyjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual = pd.read_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/Rand 35 GA articles_places mentioned.xlsx')\n"
      ],
      "metadata": {
        "id": "Ktesv0P-13FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "manual['merge'] = manual.groupby(['id'])['Location'].transform(lambda x: ', '.join(x))\n"
      ],
      "metadata": {
        "id": "qLNf2xBj1_kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual = manual.drop_duplicates(subset=['id', 'merge'])"
      ],
      "metadata": {
        "id": "-JV05m3z2p8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual = manual[['id', 'merge']]"
      ],
      "metadata": {
        "id": "f9WCxEFH21Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge = pd.merge(set_merge, manual, how='left', on='id')"
      ],
      "metadata": {
        "id": "Ii7gO8Jz25ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_merge.to_excel(\"/content/drive/MyDrive/Georgia/Locations Analysis/Validation_test/spacy_manual_validation.xlsx\")"
      ],
      "metadata": {
        "id": "NI1eMTHK3Whg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_temp = df.sample(100)"
      ],
      "metadata": {
        "id": "_gb7hW6LF7NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample_temp"
      ],
      "metadata": {
        "id": "aB57Dan-HhbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # continued from the above\n",
        "\n",
        "# # article \n",
        "# df_sample_20 = df[ ( df['place_ng1'].str.len() >= 1) | ( df['place_ng2'].str.len() >= 1) ].sample(20)\n",
        "\n",
        "\n",
        "# # place ner\n",
        "# df_sample_20 = df[ ( df['place_ner1'].str.len() >= 1) | ( df['place_ner2'].str.len() >= 1) ].sample(20)"
      ],
      "metadata": {
        "id": "61P3XUGgYKyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## article test\n",
        "\n",
        "temp_uni = df_sample_temp[(df_sample_temp['place_ng1'].str.len()) >= 1]\n",
        "temp_bi = df_sample_temp[(df_sample_temp['place_ng2'].str.len()) >= 1]\n",
        "\n",
        "temp_uni = temp_uni[['id', 'source', 'place_ng1', 'article_final']]\n",
        "temp_bi = temp_bi[['id', 'source', 'place_ng2', 'article_final']]\n",
        "\n",
        "temp_uni_df = temp_uni.explode('place_ng1')\n",
        "temp_bi_df = temp_bi.explode('place_ng2')\n",
        "\n",
        "temp_uni_df = temp_uni_df.rename(columns={'place_ng1': 'place_ner'})\n",
        "temp_bi_df = temp_bi_df.rename(columns={'place_ng2': 'place_ner'})\n",
        "\n",
        "## place ner test\n",
        "\n",
        "temp_uni2 = df_sample_temp[(df_sample_temp['place_ner1'].str.len()) >= 1]\n",
        "temp_bi2 = df_sample_temp[(df_sample_temp['place_ner2'].str.len()) >= 1]\n",
        "\n",
        "temp_uni2 = temp_uni2[['id', 'source', 'place_ner1', 'article_final']]\n",
        "temp_bi2 = temp_bi2[['id', 'source', 'place_ner2', 'article_final']]\n",
        "\n",
        "temp_uni2_df = temp_uni2.explode('place_ner1')\n",
        "temp_bi2_df = temp_bi2.explode('place_ner2')\n",
        "\n",
        "temp_uni2_df = temp_uni2_df.rename(columns={'place_ner1': 'place_ner'})\n",
        "temp_bi2_df = temp_bi2_df.rename(columns={'place_ner2': 'place_ner'})\n"
      ],
      "metadata": {
        "id": "lds-YShQbbTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df_all = pd.concat([temp_uni_df, temp_bi_df])\n",
        "temp_df2_all = pd.concat([temp_uni2_df, temp_bi2_df])"
      ],
      "metadata": {
        "id": "16x28NuScyzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "by_sentence = temp_df_all['article_final'].apply(lambda x : sent_tokenize(x)).apply(pd.Series,1).stack()\n",
        "by_sentence_df = pd.DataFrame(by_sentence)\n",
        "by_sentence_df.rename(columns={0:'sentence_each'}, inplace=True)\n",
        "\n",
        "by_sentence_df['sentence_turn'] = by_sentence_df.index.get_level_values(1)\n",
        "by_sentence_df.index = by_sentence_df.index.get_level_values(0)\n"
      ],
      "metadata": {
        "id": "jKE2BNCBYQdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_join = pd.merge(temp_df_all, by_sentence_df, left_index=True, right_index=True)\n",
        "merge_all_join2 = pd.merge(temp_df2_all, by_sentence_df, left_index=True, right_index=True)\n"
      ],
      "metadata": {
        "id": "dvcrkUODc-G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_join['place_YN'] = merge_all_join.apply(lambda x: x.place_ner in x.sentence_each, axis=1)\n",
        "merge_all_join2['place_YN'] = merge_all_join2.apply(lambda x: x.place_ner in x.sentence_each, axis=1)"
      ],
      "metadata": {
        "id": "Y7NNV7OPc7ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_join_in = merge_all_join[ (merge_all_join['place_YN']== True)]\n",
        "merge_all_join2_in = merge_all_join2[ (merge_all_join2['place_YN']== True)]\n"
      ],
      "metadata": {
        "id": "Y_yR_qgIdy14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final['place_ner'] = location_final['ner_place_clean'].copy()"
      ],
      "metadata": {
        "id": "JxyTF-hqetLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_short = location_final[['place_ner', 'county_level', 'formatted_address']]"
      ],
      "metadata": {
        "id": "lsRV5uhvfC5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_join_in = pd.merge(merge_all_join_in, location_final_short, how='left', on='place_ner')\n",
        "merge_all_join2_in = pd.merge(merge_all_join2_in, location_final_short, how='left', on='place_ner')"
      ],
      "metadata": {
        "id": "uBPg1I6XeBqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_join_in = merge_all_join_in[['id', 'source','place_ner', 'sentence_each', 'county_level', 'formatted_address']]\n",
        "merge_all_join2_in = merge_all_join2_in[['id', 'source','place_ner', 'sentence_each', 'county_level', 'formatted_address']]"
      ],
      "metadata": {
        "id": "qpOrWI5FfUFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_join_in = merge_all_join_in.drop_duplicates()\n",
        "merge_all_join2_in = merge_all_join2_in.drop_duplicates()"
      ],
      "metadata": {
        "id": "GmF49o43gXsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merge_all_join_in.to_excel('Georgia_place_sample_test_article_identification.xlsx')\n",
        "merge_all_join2_in.to_excel('Georgia_place_sample_test_spacy_ner_identification.xlsx')"
      ],
      "metadata": {
        "id": "En17dVfhfhPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(100)"
      ],
      "metadata": {
        "id": "LvQdjJt4fpdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PazaDYm-iDgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}