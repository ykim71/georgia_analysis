{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykim71/georgia_analysis/blob/main/(2)_Georgia_place_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7PpN2VVxH5c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# need access to the folder(s) below:\n",
        "\n",
        "#%cd /content/drive/MyDrive/Georgia/\n",
        "#%cd /content/drive/MyDrive/Georgia/Locations Analysis\n"
      ],
      "metadata": {
        "id": "aPvEBRBtxzje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeaiBqTzQ_Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Location analysis\n",
        "\n",
        "> Find place and location information in Georgia through NER\n",
        "\n",
        "\n",
        "> Locate exact address assisted by Google Map API through R library \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5yLkNpuLL3Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep for place analysis"
      ],
      "metadata": {
        "id": "JgTpKxDx-YMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis\n"
      ],
      "metadata": {
        "id": "PFZz3K7xSlBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('Georgia_data_v2_translation_ner3_lem.pkl') #CO: I assume this is the relevant file!"
      ],
      "metadata": {
        "id": "7WKF8OS4RkoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatization if needed\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "sp = spacy.load('en_core_web_sm', disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"])\n"
      ],
      "metadata": {
        "id": "Leu0aduT9jp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_ner_place(text):\n",
        "  text = sp(text)\n",
        "  \n",
        "  ner_list = []\n",
        "  \n",
        "  for entity in text.ents:\n",
        "    if entity.label_ == \"FAC\":\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    if entity.label_ == \"GPE\":\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    if entity.label_ == \"LOC\":\n",
        "      ner_list.append(entity.text + \" (\" + entity.label_ + \")\")\n",
        "    else:\n",
        "      None\n",
        "  return str(set(ner_list))\n"
      ],
      "metadata": {
        "id": "r2S86oeO-Pqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ner_places'] = df['article_final'].astype(str).apply(text_ner_place)"
      ],
      "metadata": {
        "id": "ydmHijaN-WNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "kQ9DlL0sdLJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_pickle('Georgia_data_v2_translation_ner3_lem.pkl') "
      ],
      "metadata": {
        "id": "lKyUNAawaALt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find rough location from spaCy"
      ],
      "metadata": {
        "id": "R2H0iUp_X1Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('Georgia_data_v2_translation_ner3_lem.pkl')\n"
      ],
      "metadata": {
        "id": "vh4PyWlOX0Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ner = df.loc[df['ner_places'] != 'set()'] "
      ],
      "metadata": {
        "id": "yy41J8P9PlYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "print(len(df_ner))"
      ],
      "metadata": {
        "id": "Uj_17ZSjQeRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand = df_ner['ner_places'].str.split(',').explode().str.strip('{} ')\n"
      ],
      "metadata": {
        "id": "ucqy79j7QbkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand = pd.DataFrame(df_expand)\n",
        "print(df_expand) # note that there's error of spaCy that capture places and person in GPE/LOC/FAC and PERSON "
      ],
      "metadata": {
        "id": "pLmMPrC4Qo0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand['ner_places_clean'] = df_expand['ner_places'].str.replace(r\"\\'\",\"\")\n",
        "df_expand['ner_places_clean'] = df_expand['ner_places_clean'].str.replace(r\" \\\"\",\"\")\n",
        "df_expand['ner_places_clean'] = df_expand['ner_places_clean'].str.replace(r\"\\\"\",\"\")\n",
        "df_expand['ner_places_clean'] = df_expand['ner_places_clean'].str.replace(r\"\\(.*\\)\",\"\")"
      ],
      "metadata": {
        "id": "NPh4arGwQqEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_expand_count = df_expand.groupby('ner_places_clean').count().reset_index()\n",
        "df_expand_count "
      ],
      "metadata": {
        "id": "40t2DcFSRamc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NER entities appeared >= 5 across articles \n",
        "\n",
        "df_freq_n5 = df_expand_count[df_expand_count[\"ner_places\"] >= 5]\n",
        "df_freq_n5.to_excel('df_freq_n5_ner_v2.xlsx')\n"
      ],
      "metadata": {
        "id": "fdLEo3K0Rt71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # compare place entities with v1\n",
        "\n",
        "# df_freq_n5_v2 = pd.read_excel('df_freq_n5_ner_v2.xlsx')\n",
        "# df_freq_n5_v1 = pd.read_excel('df_freq_n5_ner.xlsx')\n",
        "\n",
        "# df_freq_n5_v1['version'] = 'v1'\n",
        "# df_freq_n5_v2['version'] = 'v2'\n",
        "\n",
        "# df_freq_n5_merge = pd.merge( df_freq_n5_v1,df_freq_n5_v2, how=\"outer\", on=[\"ner_places_clean\"])"
      ],
      "metadata": {
        "id": "TG-YAtO6xsDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find sentence example of location"
      ],
      "metadata": {
        "id": "Ggu0MvMFQmx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #CO: already imported.\n",
        "\n",
        "#ner_places = pd.read_csv('Georgia_ner_places.csv') # previous data\n",
        "ner_places = pd.read_csv('Locations Analysis/Georgia_ner_places_v2.xlsx') # updated data; added all possible address from Google Map API"
      ],
      "metadata": {
        "id": "ZU1S_6coQpR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_places['ner_places_clean'] = ner_places['ner_places_clean'].str.rstrip()"
      ],
      "metadata": {
        "id": "Dd9WWAzOR4D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_places_all = list(set(ner_places['ner_places_clean'].tolist())) "
      ],
      "metadata": {
        "id": "XLlz4OzHRpob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "EWfelpd-Q7zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df[\"id\"] = df.index + 1\n",
        "df_ner = df.loc[df['ner_places'] != 'set()'] #CO: This step has already been done once above (in chunk 21)"
      ],
      "metadata": {
        "id": "pqUoeTQCQ_aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "df_ner['place_ng1'] = df_ner['article_final'].astype(str).apply(lambda x: [i for i in ner_places_all if i in x]) # make a separate column to search those words in another article column\n"
      ],
      "metadata": {
        "id": "3ChBQadJQ4LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df_uni_dict = df_ner[['id',  'place_ng1']]\n",
        "text_df_uni_article = df_ner[['id', \"article_final\"]]\n"
      ],
      "metadata": {
        "id": "-xeJVvdJgd5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CO: not sure why we're taking a sample sentence here. Can't tell based on this code how this is a sample.\n",
        "sample_sentence = text_df_uni_dict['place_ng1'].astype(str).str.split(',').explode().str.strip('[] ')\n",
        "sample_sentence_df = pd.DataFrame(sample_sentence)"
      ],
      "metadata": {
        "id": "YI4Sb5o_gf0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merge_uni = pd.merge(sample_sentence_df, text_df_uni_article, left_index=True, right_index=True)\n",
        "\n",
        "merge_uni['place_ng1'] = merge_uni['place_ng1'].str.strip('\\'')\n",
        "#CO: recommend printing merge_uni to check that it looks as you expect. Same for the objects created in the next few chunks."
      ],
      "metadata": {
        "id": "XG3Hpg9GTFFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_count = merge_uni.groupby('place_ng1').count() #\n"
      ],
      "metadata": {
        "id": "fcHSmbdKb_DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# articles mentioned a location less than 3\n",
        "merge_uni_count_l3 = merge_uni_count[merge_uni_count['article_final'] < 3].reset_index() # the threshold is for sample arbitrary 3 sentences for manual checking;\n"
      ],
      "metadata": {
        "id": "7mMK-srPLvtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_count_l3_places = merge_uni_count_l3.place_ng1.values.tolist()\n",
        "merge_uni_count_l3_places"
      ],
      "metadata": {
        "id": "9GCZ_VtNLyt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_l3 = merge_uni[merge_uni['place_ng1'].isin(merge_uni_count_l3_places)]\n",
        "merge_uni_l3_group = merge_uni_l3.groupby('place_ng1').apply(lambda x: x.sample(3, replace=True)).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7Nb6l6aAcraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# articles mentioned a location more than 3 --> random sample\n",
        "\n",
        "merge_uni_m3 = merge_uni[~merge_uni['place_ng1'].isin(merge_uni_count_l3_places)]\n",
        "merge_uni_m3_group = merge_uni_m3.groupby('place_ng1').apply(lambda x: x.sample(3, replace=False)).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "ikE7eLK3L4eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge 3 samples + those with less than 3 \n",
        "merge_uni_m3_group2 = pd.concat([merge_uni_m3_group, merge_uni_l3_group]).reset_index()"
      ],
      "metadata": {
        "id": "TrUO6epMhDjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_m3_group2.rename(columns={'place_ng1':'places'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "TdAGYk_AhPdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_uni_m3_group2"
      ],
      "metadata": {
        "id": "vYjcABVpd-I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split an article into sentences\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "by_sentence = merge_uni_m3_group2['article_final'].apply(lambda x : sent_tokenize(x)).apply(pd.Series,1).stack()\n",
        "by_sentence_df = pd.DataFrame(by_sentence)\n",
        "by_sentence_df.rename(columns={0:'sentence_each'}, inplace=True)\n",
        "\n",
        "by_sentence_df['sentence_turn'] = by_sentence_df.index.get_level_values(1)\n",
        "by_sentence_df.index = by_sentence_df.index.get_level_values(0)\n"
      ],
      "metadata": {
        "id": "NVb3pCFWhLSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "by_sentence_df"
      ],
      "metadata": {
        "id": "3JYgzu7hde2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging split sentences to the article level\n",
        "merge_all_m3_join = pd.concat([merge_uni_m3_group2, by_sentence_df], axis=1)\n"
      ],
      "metadata": {
        "id": "Ol3WC85ghWgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_m3_join['search_words'] = merge_all_m3_join.apply(lambda x: x.places in x.sentence_each, axis=1)\n"
      ],
      "metadata": {
        "id": "y1l5DuylhZXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_all_m3_join['article_id'] = merge_all_m3_join.index.get_level_values(0)\n",
        "merge_all_m3_join.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "KxrA6OwDWX3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find those sentences that contain searching words (locations)\n",
        "\n",
        "merge_all_m3_join_TRUE = merge_all_m3_join[merge_all_m3_join['search_words']==True]"
      ],
      "metadata": {
        "id": "Wd_SJ1biiBUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp = merge_all_m3_join_TRUE.groupby('places')['id'].count() # first empty row is because of white space considered as a word\n"
      ],
      "metadata": {
        "id": "V7b9pXkwTeHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract 3 random sentences containing the searching word (location) only\n",
        "\n",
        "merge_temp_m3_group = merge_all_m3_join_TRUE.groupby('places').apply(lambda x: x.sample(3, replace=False)).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "jYGpxaBwTso8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_m3_group"
      ],
      "metadata": {
        "id": "Ns4uUaC0er4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_m3_group2 = merge_temp_m3_group[['places','id','sentence_each']]"
      ],
      "metadata": {
        "id": "IuA8GtipjnN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_m3_group2['domainId'] = merge_temp_m3_group2.groupby('places')['places'].rank(method='first')\n"
      ],
      "metadata": {
        "id": "H_ta7WfUkRgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_m3_group2.sort_values('places')"
      ],
      "metadata": {
        "id": "BiNKPGHkmz-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spreading dataset with 3 different sentences as columns\n",
        "\n",
        "merge_temp_m3_group2_pivot = merge_temp_m3_group2.pivot(index='places', columns = 'domainId', values='sentence_each').reset_index() "
      ],
      "metadata": {
        "id": "9ZfRNhH_jB-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_m3_group2_pivot.rename(columns={1:'sent_1', 2:'sent_2', 3:'sent_3'}, inplace=True)\n",
        "merge_temp_m3_group2_pivot "
      ],
      "metadata": {
        "id": "s7DqboNzUDOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_places['places'] = ner_places['ner_places_clean']"
      ],
      "metadata": {
        "id": "wwHdQ-R7iony"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_final = pd.merge(ner_places, merge_temp_m3_group2_pivot, on=\"places\", how='left').reset_index()\n",
        "#CO: recommend printing this. Does it look as expected?"
      ],
      "metadata": {
        "id": "zDopHL8lnnGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_final['sent_1'] = merge_temp_final['sent_1'].str.replace('\\n', ' ')\n",
        "merge_temp_final['sent_2'] = merge_temp_final['sent_2'].str.replace('\\n', ' ')\n",
        "merge_temp_final['sent_3'] = merge_temp_final['sent_3'].str.replace('\\n', ' ')"
      ],
      "metadata": {
        "id": "rEJHlTVfhavY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_temp_final.to_excel('/content/drive/MyDrive/Georgia/Locations Analysis/Georgia_ner_places_v2_wsent.xlsx') "
      ],
      "metadata": {
        "id": "Z2lYrXCaprjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look up location (w updated data) on articles"
      ],
      "metadata": {
        "id": "cY1vi4e0QNqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Georgia/Locations Analysis"
      ],
      "metadata": {
        "id": "rEsOC72WTTib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data created by manual coding\n",
        "import pandas as pd\n",
        "\n",
        "location_final = pd.read_excel('Georgia_place_validation_counties.xlsx') # these are only places in GA"
      ],
      "metadata": {
        "id": "6vkKM1LjQRXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final = location_final[location_final['final_selection']==1]"
      ],
      "metadata": {
        "id": "IhdmM7NvcwJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st = location_final[['ner_place_clean','county_level', 'final_selection']]"
      ],
      "metadata": {
        "id": "qYuxviOCj0FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st = location_final_st.dropna()"
      ],
      "metadata": {
        "id": "l7_56rt2yiVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(location_final)) #CO: include this, so we can tell how many are being dropped\n",
        "print(len(location_final_st))"
      ],
      "metadata": {
        "id": "AzUCzxNbmsBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st"
      ],
      "metadata": {
        "id": "MyGCPiwxPcuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # multiple counties deleted\n",
        "# location_final_st = location_final_st[location_final_st['county_level'].str.contains('Counties')==False]"
      ],
      "metadata": {
        "id": "cKbOXVZsmb1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(location_final_st.county_level.values.tolist()))"
      ],
      "metadata": {
        "id": "hFPKsq8gsiaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_list = list(set(location_final_st['ner_place_clean'].tolist()))"
      ],
      "metadata": {
        "id": "d3UqVKMGgFCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle('/content/drive/MyDrive/Georgia/Web Scraping/Georgia_data_v2_translation_ner2_lem.pkl')\n"
      ],
      "metadata": {
        "id": "opLFb-2OdJzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "def bigrams(s):\n",
        "    return [i for i in s if re.search(r'\\s', i) ]\n",
        "  \n",
        "def unigrams(s):\n",
        "    return [i for i in s if not re.search(r'\\s', i) ]\n",
        "\n",
        "word_bigrams_done = list(set(bigrams(location_final_list)))\n",
        "print(word_bigrams_done) #CO: some of these don't really seem to be bigrams. For example: 'Mill Creek High School Football Game'\n",
        "print(len(word_bigrams_done))\n",
        "                       \n",
        "word_unigrams_done = unigrams(location_final_list)\n",
        "print(word_unigrams_done)\n",
        "print(len(word_unigrams_done)) #CO: why are there more bigrams than unigrams? Conceptually, wouldn't we expect at least as mnay unigrams? I'm probably just missing something, but I'll mention it in case it's helpful to take a second look at!\n"
      ],
      "metadata": {
        "id": "hbjFlI7bdKsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "df['place_ng1'] = df['article_final'].astype(str).apply(lambda x: set.intersection(set(x.split(' ')), word_unigrams_done))\n",
        "df['place_ng2'] = df['article_final'].astype(str).apply(lambda x: [i for i in word_bigrams_done if i in x])\n"
      ],
      "metadata": {
        "id": "NuLnSpGCgXyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_uni = df[(df['place_ng1'].str.len()) >= 1]\n",
        "df_bi = df[(df['place_ng2'].str.len()) >= 1]\n",
        "\n",
        "df_uni = df_uni[['id', 'source', 'place_ng1']]\n",
        "df_bi = df_bi[['id', 'source', 'place_ng2']]\n",
        "\n",
        "df_uni_df = df_uni.explode('place_ng1')\n",
        "df_bi_df = df_bi.explode('place_ng2')\n",
        "\n",
        "df_uni_df = df_uni_df.rename(columns={'place_ng1': 'place_ner'})\n",
        "df_bi_df = df_bi_df.rename(columns={'place_ng2': 'place_ner'})\n"
      ],
      "metadata": {
        "id": "83NMMSwcggCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_uni_df #CO: most these seem to be names of people (Allen, Charles, Rebecca, Philips, etc.), not places. \n",
        "df_bi_df #CO: these generally look more relevant than the unigrams"
      ],
      "metadata": {
        "id": "pM5IGXKyrDKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all = pd.concat([df_uni_df, df_bi_df])\n"
      ],
      "metadata": {
        "id": "FbOHNB_whKXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = df_ng_all.groupby(['source'])['place_ner'].count() \n"
      ],
      "metadata": {
        "id": "xDdANgf1hdTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_20 = count[count['place_ner'] >= 20].reset_index() # 20 as an arbitrary reference to cut\n",
        "count_20\n"
      ],
      "metadata": {
        "id": "tHu85ziIhfyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_20_id = list(set(count_20['source'].tolist()))\n",
        "\n",
        "df_ng_all_m20 = df_ng_all[df_ng_all['source'].isin(count_20_id)]\n",
        "df_ng_all_m20 \n"
      ],
      "metadata": {
        "id": "IvB7I52rhsHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(count_20_id)"
      ],
      "metadata": {
        "id": "1awRlpXFkXzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_final_st = location_final_st.rename(columns={'ner_place_clean': 'place_ner'})\n",
        "location_final_st #CO: should the two columns correspond to each other? If so, how do we know that they do? Is this what was manually validated earlier on?\n"
      ],
      "metadata": {
        "id": "imJj-NCGkOZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county = pd.merge(df_ng_all_m20, location_final_st, how='left', on='place_ner')\n",
        "df_ng_all_m20_county"
      ],
      "metadata": {
        "id": "Ry1nnH47h1h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county"
      ],
      "metadata": {
        "id": "qiK6jMxOjoGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop duplicates to count the same county with different places \n",
        "\n",
        "df_ng_all_m20_county_unique = df_ng_all_m20_county.drop_duplicates(subset=['id', 'source', 'county_level']) "
      ],
      "metadata": {
        "id": "qeTXN7_YkrEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county_unique"
      ],
      "metadata": {
        "id": "sWtC5Fwow1kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ng_all_m20_county_unique_count = df_ng_all_m20_county_unique.groupby(['source','county_level'])['id'].count().reset_index()\n",
        "df_ng_all_m20_county_unique_count"
      ],
      "metadata": {
        "id": "RC6nhVn2lbLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename article count back\n",
        "\n",
        "df_ng_all_m20_county_unique_count = df_ng_all_m20_county_unique_count.rename(columns={'id': 'article_id_count'})\n",
        "df_ng_all_m20_county_unique_count\n"
      ],
      "metadata": {
        "id": "yfmDfAVDfV6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_ng_all_m20_county_unique_count.to_excel('Georgia_m20_county_unique_count_v2.xlsx')\n"
      ],
      "metadata": {
        "id": "ZyOM2c0klvSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}